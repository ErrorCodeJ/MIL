{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqDlHGtFx9Bt"
   },
   "source": [
    "### 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741155514797,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "CA-MM2jYxczK"
   },
   "outputs": [],
   "source": [
    "import torch  ##PyTorch 라이브러리 임포트 ( 딥러닝 프레임워크 )\n",
    "from torch.utils.data import Dataset, DataLoader  ## 데이터셋과 데이터로더를 위한 모듈 임포트\n",
    "import pandas as pd  ## 데이터프레임 처리를 위한 pandas 라이브러리 임포트\n",
    "import numpy as np  ## 배열 연산을 위한 numpy 라이브러리 임포트\n",
    "\n",
    "## ASL 데이터셋 클래스 정의 (PyTorch의 Dataset 클래스를 상속)\n",
    "class ASL_Dataset(Dataset):  \n",
    "  def __init__(self, path):\n",
    "    super(ASL_Dataset, self).__init__()  ## 부모 클래스 ( Dataset )의 초기화 메서드 호출\n",
    "\n",
    "## CSV 파일을 읽어 데이터프레임으로 로드\n",
    "    df = pd.read_csv(path)\n",
    "    self.y = df['label']  ## 'label' 열을 추출 -> 타겟 변수 ( y )로 설정\n",
    "    del df['label']  ## 데이터프레임에서 'label' 열 삭제 ( 입력 데이터만 남김 )\n",
    "    self.x = df.values  ## 나머지 데이터를 numpy 배열로 변환하여 입력 변수 ( x )로 설정\n",
    "\n",
    "\n",
    "## 데이터에서 특정 인덱스의 샘플을 반환하는 메서드\n",
    "  def __getitem__(self, index):\n",
    "    x_sample = np.uint8( self.x[index].reshape(28,28) )  ## 입력 데이터를 28X28 크기의 이미지로 재구성 ( uint8 타입으로 변경 )\n",
    "    x_tensor = torch.tensor ( x_sample[np.newaxis,:,:] ).float()  ## 단일 채널 ( 1차원 )을 추가하여 텐서로 변환 ( 형식 : [1, 28, 28]), float 타입으로 변환\n",
    "    y_tensor = torch.tensor ( self.y[index] )  ## 해당 인덱스의 레이블을 텐서로 변환\n",
    "    return x_tensor, y_tensor  ## 입력 텐서와 레이블 텐서를 튜플로 반환\n",
    "\n",
    "\n",
    "## 데이터셋의 전체 길이 ( 샘플 수 )를 반환하는 메서드\n",
    "  def __len__(self):\n",
    "    return self.x.shape[0]  ## 입력 데이터의 행 개수( 샘플 수 ) 반환환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4097,
     "status": "ok",
     "timestamp": 1741155521105,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "DsfiYTH30khJ"
   },
   "outputs": [],
   "source": [
    "## 훈련 데이터셋 객체 생성 ( sign_mnist_train.csv 파일을 기반으로 ASL_Dataset 인스턴스 생성 )\n",
    "train_data = ASL_Dataset(\"sign_mnist_train.csv\")\n",
    "\n",
    "## 검증 데이터셋 객제 생성 ( sign_mnist_valid.csv 파일을 기반으로 ASL_Dataset 인스턴스 생성 )\n",
    "valid_data = ASL_Dataset(\"sign_mnist_valid.csv\")\n",
    "\n",
    "## 훈련 데이터로드 생성\n",
    "## - dataset : 생성할 데이터셋 ( train_data )\n",
    "## - batch_size :  한 번에 처리할 샘플 수 ( 1000개 )\n",
    "## - shuffle : 데이터 무작위로 섞을지 여부 ( True로 설정하여 섞음 )\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1000, shuffle=True)\n",
    "\n",
    "## 검증 데이터로더 생성\n",
    "## - datastet : 사용할 데이터셋 ( valid_data )\n",
    "## - batch_size : 한 번에 처리할 샘플 수 ( 1000개 )\n",
    "## - shuffle : 데이터 무작위로 섞을지 여부 ( False로 설정하여 섞지 않음 )\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIKhFmgy1rvS"
   },
   "source": [
    "### 2. 뉴럴네트워크 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741155876185,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "jRLpynwG1xn2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "      ## 첫 번째 합성곱 층 : 입력 채널 1 , 출력체널 16 , 커널 크기 3x3 , 패딩 1\n",
    "      self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "      ## 두 번째 합성곱 층 : 입력 채널 16 , 출력체널 32 , 커널 크기 3x3 , 패딩 1\n",
    "      self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "      ## 세 번째 합성곱 층 : 입력 채널 32 , 출력체널 32 , 커널 크기 3x3 , 패딩 1\n",
    "      self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "      ## 활성화 함수 : ReLU ( 음수를 0으로 바꿔줌 )\n",
    "      self.relu = nn.ReLU()\n",
    "      ## 최대 풀링 : 2X2 크기로 특징 맵 크기를 줄임\n",
    "      self.pool = nn.MaxPool2d(2,2)\n",
    "      ## 완전 연결 층 : 입력 크기 7*7&32 , 출력 크기 24\n",
    "      self.fc = nn.Linear(7*7*32, 24)\n",
    "\n",
    "  def forward(self, x):\n",
    "    ## 첫 번째 합성곱 층을 통과하고 ReLU 적용\n",
    "    x = self.relu( self.conv1(x) )\n",
    "    ## 풀링을 통해 크기 감소 : 14X14X16\n",
    "    x = self.pool(x)   # 14X14X16\n",
    "    ## 두 번째 함성곱 층을 통과하고 ReLU 적용\n",
    "    x = self.relu( self.conv2(x) )\n",
    "    ## 풀링을 통해 크기 감소 7X7X32\n",
    "    x = self.pool(x)   # 7X7X32\n",
    "    ## 세번째 합성곱 층을 통과하고 ReLU 적용 : 7X7X32\n",
    "    x = self.relu( self.conv3(x) )   # 7x7x32\n",
    "\n",
    "    ## 텐서를 1차원으로 펼침 : 배치 크기 X ( 7*7*32 )\n",
    "    x = x.view(-1, 7*7*32)\n",
    "    ## 완전 연결 층을 통과하여 최종 출력 생성\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1741155877349,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "hW9Disox6s5E"
   },
   "outputs": [],
   "source": [
    "## Net 클래스의 인스턴스를 생성하여 convnet 변수에 할당\n",
    "convnet = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-bB4XRP7cvz"
   },
   "source": [
    "### 3.손실함수와 최적화함수의 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6988,
     "status": "ok",
     "timestamp": 1741156104024,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "nz1azYDJ7gH-"
   },
   "outputs": [],
   "source": [
    "## 손실 함수 정의 : 크로스 엔트로피 손실 ( 분류 문제에 적합 )\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "## 최적화 도구 정의 : Adam 알고리즘 사용 ,학습률 0.001로 설정 , convnet의 파라미터를 최적화\n",
    "optimizer = torch.optim.Adam(convnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVRH4HUs7463"
   },
   "source": [
    "### 4. 뉴럴네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107209,
     "status": "ok",
     "timestamp": 1741156241962,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "4d45fk4s77Wk",
    "outputId": "7ef6087c-5103-4ad2-f941-6577bf862c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  , Loss: 139.78275990486145\n",
      "Epoch: 2  , Loss: 41.181666135787964\n",
      "Epoch: 3  , Loss: 12.290689006447792\n",
      "Epoch: 4  , Loss: 4.458873055875301\n",
      "Epoch: 5  , Loss: 1.911327749490738\n"
     ]
    }
   ],
   "source": [
    "## 5번의 에포크 동안 학습 반복\n",
    "for epoch in range(5):\n",
    "    ## 손실 값을 저장할 변수 초기화\n",
    "    loss_val = 0\n",
    "    ## 데이터 로더에서 배치 단위로 데이터를 가져와 반복\n",
    "    for itr, data in enumerate(train_loader):\n",
    "        ## 옵티마이저의 기울기 초기화 ( 이전 기울기 제거 )\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ##데이터에서 입력과 레이블 분리\n",
    "        inputs, labels = data\n",
    "        ##신경망을 통해 예측값 계싼\n",
    "        pred = convnet(inputs)\n",
    "        \n",
    "        ## 예측값과 실제 레이블 간의 손실 계산\n",
    "        loss = loss_function(pred, labels)\n",
    "\n",
    "        ## 손실에 대한 기울기 계산 ( 역전파 )\n",
    "        loss.backward()\n",
    "\n",
    "        ## 기울기를 바탕으로 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        ## 이번 배치의 손실 값을 누적\n",
    "        loss_val += loss.item()\n",
    "\n",
    "    ## 에포크 종료 후 손실 값 출력    \n",
    "    print(\"Epoch:\", epoch+1, \" , Loss:\", loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxqlgXYrAFxy"
   },
   "source": [
    "### 5. 뉴럴네트워크 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3715,
     "status": "ok",
     "timestamp": 1741156473144,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "MjONcPJGAI15",
    "outputId": "cc382e27-6537-4ee1-e211-07cbba24cac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.8623814835471277\n"
     ]
    }
   ],
   "source": [
    "## 예측값과 실제 레이블을 저장할 리스트 초기화\n",
    "pred_list = []\n",
    "label_list = []\n",
    "## 검증 데이터 로더에서 배치 단위로 데이터를 가져와 반복\n",
    "for itr, data in enumerate(valid_loader):\n",
    "  ## 데이터에서 입력과 레이블 분리\n",
    "  inputs, labels = data\n",
    "  ## 신경망을 통해 검증 데이터에 대한 예측값 계산\n",
    "  pred_test = convnet(inputs)\n",
    "  ## 각 예측값에서 가장 높은 확률을 가진 카테고리 선택\n",
    "  pred_category = torch.argmax(pred_test, dim=1)\n",
    "\n",
    "  ## 예측 카테고리와 레이블을 리스트에 추가\n",
    "  pred_list = pred_list + list(pred_category)\n",
    "  label_list = label_list + list(labels)\n",
    "\n",
    "## 예측값과 실제 레이블 간 일치 여부를 계산하여 정확도 도출\n",
    "accu = np.mean( np.array(pred_list) ==np.array(label_list) )\n",
    "## 검증 데이터에 대한 정확도 출력\n",
    "print(\"Test accuracy: \", accu)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPK3oWJZRotxhoQ1aUQr9ip",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
