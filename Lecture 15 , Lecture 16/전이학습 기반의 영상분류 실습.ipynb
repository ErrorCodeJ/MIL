{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJHpMJKO5uyl"
   },
   "source": [
    "### 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2968,
     "status": "ok",
     "timestamp": 1741238545087,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "nV-bi6Ec5x4o",
    "outputId": "70e8347c-b752-4f44-feda-187b7a61bcb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-26ubuntu3.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
      "Archive:  dog.zip\n",
      "  inflating: train/bo/bo_1.jpg       \n",
      "  inflating: train/bo/bo_10.jpg      \n",
      "  inflating: train/bo/bo_11.jpg      \n",
      "  inflating: train/bo/bo_12.jpg      \n",
      " extracting: train/bo/bo_13.jpg      \n",
      "  inflating: train/bo/bo_14.jpg      \n",
      "  inflating: train/bo/bo_15.jpg      \n",
      "  inflating: train/bo/bo_16.jpg      \n",
      "  inflating: train/bo/bo_17.jpg      \n",
      "  inflating: train/bo/bo_18.jpg      \n",
      "  inflating: train/bo/bo_19.jpg      \n",
      "  inflating: train/bo/bo_2.jpg       \n",
      "  inflating: train/bo/bo_3.jpg       \n",
      "  inflating: train/bo/bo_4.jpg       \n",
      "  inflating: train/bo/bo_5.jpg       \n",
      "  inflating: train/bo/bo_6.jpg       \n",
      "  inflating: train/bo/bo_7.jpg       \n",
      "  inflating: train/bo/bo_8.jpg       \n",
      "  inflating: train/bo/bo_9.jpg       \n",
      "  inflating: train/not_bo/1.jpg      \n",
      "  inflating: train/not_bo/10.jpg     \n",
      "  inflating: train/not_bo/100.jpg    \n",
      "  inflating: train/not_bo/101.jpg    \n",
      "  inflating: train/not_bo/102.jpg    \n",
      "  inflating: train/not_bo/103.jpg    \n",
      "  inflating: train/not_bo/104.jpg    \n",
      "  inflating: train/not_bo/105.jpg    \n",
      "  inflating: train/not_bo/106.jpg    \n",
      "  inflating: train/not_bo/107.jpg    \n",
      "  inflating: train/not_bo/108.jpg    \n",
      "  inflating: train/not_bo/109.jpg    \n",
      "  inflating: train/not_bo/11.jpg     \n",
      "  inflating: train/not_bo/110.jpg    \n",
      "  inflating: train/not_bo/111.jpg    \n",
      "  inflating: train/not_bo/112.jpg    \n",
      "  inflating: train/not_bo/113.jpg    \n",
      "  inflating: train/not_bo/114.jpg    \n",
      "  inflating: train/not_bo/115.jpg    \n",
      "  inflating: train/not_bo/116.jpg    \n",
      "  inflating: train/not_bo/117.jpg    \n",
      "  inflating: train/not_bo/118.jpg    \n",
      "  inflating: train/not_bo/119.jpg    \n",
      "  inflating: train/not_bo/12.jpg     \n",
      "  inflating: train/not_bo/120.jpg    \n",
      "  inflating: train/not_bo/13.jpg     \n",
      "  inflating: train/not_bo/14.jpg     \n",
      "  inflating: train/not_bo/15.jpg     \n",
      "  inflating: train/not_bo/16.jpg     \n",
      "  inflating: train/not_bo/17.jpg     \n",
      "  inflating: train/not_bo/18.jpg     \n",
      "  inflating: train/not_bo/19.jpg     \n",
      "  inflating: train/not_bo/2.jpg      \n",
      "  inflating: train/not_bo/20.jpg     \n",
      "  inflating: train/not_bo/21.jpg     \n",
      "  inflating: train/not_bo/22.jpg     \n",
      "  inflating: train/not_bo/23.jpg     \n",
      "  inflating: train/not_bo/24.jpg     \n",
      "  inflating: train/not_bo/25.jpg     \n",
      "  inflating: train/not_bo/26.jpg     \n",
      "  inflating: train/not_bo/27.jpg     \n",
      "  inflating: train/not_bo/28.jpg     \n",
      "  inflating: train/not_bo/29.jpg     \n",
      "  inflating: train/not_bo/3.jpg      \n",
      "  inflating: train/not_bo/30.jpg     \n",
      "  inflating: train/not_bo/31.jpg     \n",
      "  inflating: train/not_bo/32.jpg     \n",
      "  inflating: train/not_bo/33.jpg     \n",
      "  inflating: train/not_bo/34.jpg     \n",
      "  inflating: train/not_bo/35.jpg     \n",
      "  inflating: train/not_bo/36.jpg     \n",
      "  inflating: train/not_bo/37.jpg     \n",
      "  inflating: train/not_bo/38.jpg     \n",
      "  inflating: train/not_bo/39.jpg     \n",
      "  inflating: train/not_bo/4.jpg      \n",
      "  inflating: train/not_bo/40.jpg     \n",
      "  inflating: train/not_bo/41.jpg     \n",
      "  inflating: train/not_bo/42.jpg     \n",
      "  inflating: train/not_bo/43.jpg     \n",
      "  inflating: train/not_bo/44.jpg     \n",
      "  inflating: train/not_bo/45.jpg     \n",
      "  inflating: train/not_bo/46.jpg     \n",
      "  inflating: train/not_bo/47.jpg     \n",
      "  inflating: train/not_bo/48.jpg     \n",
      "  inflating: train/not_bo/49.jpg     \n",
      "  inflating: train/not_bo/5.jpg      \n",
      "  inflating: train/not_bo/50.jpg     \n",
      "  inflating: train/not_bo/51.jpg     \n",
      "  inflating: train/not_bo/52.jpg     \n",
      "  inflating: train/not_bo/53.jpg     \n",
      "  inflating: train/not_bo/54.jpg     \n",
      "  inflating: train/not_bo/55.jpg     \n",
      "  inflating: train/not_bo/56.jpg     \n",
      "  inflating: train/not_bo/57.jpg     \n",
      "  inflating: train/not_bo/58.jpg     \n",
      "  inflating: train/not_bo/59.jpg     \n",
      "  inflating: train/not_bo/6.jpg      \n",
      "  inflating: train/not_bo/60.jpg     \n",
      "  inflating: train/not_bo/61.jpg     \n",
      "  inflating: train/not_bo/62.jpg     \n",
      "  inflating: train/not_bo/63.jpg     \n",
      "  inflating: train/not_bo/64.jpg     \n",
      "  inflating: train/not_bo/65.jpg     \n",
      "  inflating: train/not_bo/66.jpg     \n",
      "  inflating: train/not_bo/67.jpg     \n",
      "  inflating: train/not_bo/68.jpg     \n",
      "  inflating: train/not_bo/69.jpg     \n",
      "  inflating: train/not_bo/7.jpg      \n",
      "  inflating: train/not_bo/70.jpg     \n",
      "  inflating: train/not_bo/71.jpg     \n",
      "  inflating: train/not_bo/72.jpg     \n",
      "  inflating: train/not_bo/73.jpg     \n",
      "  inflating: train/not_bo/74.jpg     \n",
      "  inflating: train/not_bo/75.jpg     \n",
      "  inflating: train/not_bo/76.jpg     \n",
      "  inflating: train/not_bo/77.jpg     \n",
      "  inflating: train/not_bo/78.jpg     \n",
      "  inflating: train/not_bo/79.jpg     \n",
      "  inflating: train/not_bo/8.jpg      \n",
      "  inflating: train/not_bo/80.jpg     \n",
      "  inflating: train/not_bo/81.jpg     \n",
      "  inflating: train/not_bo/82.jpg     \n",
      "  inflating: train/not_bo/83.jpg     \n",
      "  inflating: train/not_bo/84.jpg     \n",
      "  inflating: train/not_bo/85.jpg     \n",
      "  inflating: train/not_bo/86.jpg     \n",
      "  inflating: train/not_bo/87.jpg     \n",
      "  inflating: train/not_bo/88.jpg     \n",
      "  inflating: train/not_bo/89.jpg     \n",
      "  inflating: train/not_bo/9.jpg      \n",
      "  inflating: train/not_bo/90.jpg     \n",
      "  inflating: train/not_bo/91.jpg     \n",
      "  inflating: train/not_bo/92.jpg     \n",
      "  inflating: train/not_bo/93.jpg     \n",
      "  inflating: train/not_bo/94.jpg     \n",
      "  inflating: train/not_bo/95.jpg     \n",
      "  inflating: train/not_bo/96.jpg     \n",
      "  inflating: train/not_bo/97.jpg     \n",
      "  inflating: train/not_bo/98.jpg     \n",
      "  inflating: train/not_bo/99.jpg     \n",
      "  inflating: valid/bo/bo_20.jpg      \n",
      "  inflating: valid/bo/bo_21.jpg      \n",
      "  inflating: valid/bo/bo_22.jpg      \n",
      " extracting: valid/bo/bo_23.jpg      \n",
      "  inflating: valid/bo/bo_24.jpg      \n",
      "  inflating: valid/bo/bo_25.jpg      \n",
      "  inflating: valid/bo/bo_26.jpg      \n",
      "  inflating: valid/bo/bo_27.jpg      \n",
      "  inflating: valid/bo/bo_28.jpg      \n",
      "  inflating: valid/bo/bo_29.jpg      \n",
      "  inflating: valid/not_bo/121.jpg    \n",
      "  inflating: valid/not_bo/122.jpg    \n",
      "  inflating: valid/not_bo/123.jpg    \n",
      "  inflating: valid/not_bo/124.jpg    \n",
      "  inflating: valid/not_bo/125.jpg    \n",
      "  inflating: valid/not_bo/126.jpg    \n",
      "  inflating: valid/not_bo/127.jpg    \n",
      "  inflating: valid/not_bo/128.jpg    \n",
      "  inflating: valid/not_bo/129.jpg    \n",
      "  inflating: valid/not_bo/130.jpg    \n",
      "  inflating: valid/not_bo/131.jpg    \n",
      "  inflating: valid/not_bo/132.jpg    \n",
      "  inflating: valid/not_bo/133.jpg    \n",
      "  inflating: valid/not_bo/134.jpg    \n",
      "  inflating: valid/not_bo/135.jpg    \n",
      "  inflating: valid/not_bo/136.jpg    \n",
      "  inflating: valid/not_bo/137.jpg    \n",
      "  inflating: valid/not_bo/138.jpg    \n",
      "  inflating: valid/not_bo/139.jpg    \n",
      "  inflating: valid/not_bo/140.jpg    \n"
     ]
    }
   ],
   "source": [
    "!apt install unzip\n",
    "!unzip dog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1741239447678,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "mzMlfQ6l6GTu"
   },
   "outputs": [],
   "source": [
    "import numpy as np  ## NumPy 라이브러리를 가져와 배열 및 행렬 연산을 수행\n",
    "import cv2  ## OpenCV 라이브러리를 가져와 이미지 처리 및 컴퓨터 비전 작업을 수행\n",
    "import glob ## glob 모듈을 가져와 파일경로 패턴 매칭을 수행\n",
    "from PIL import Image  ## PIL(Python Imaging Library)에서 Image 모듈을 가져와 이미지 파일을 처리\n",
    "\n",
    "import torch  ## PyTorch 라이브러리를 가져와 딥러닝 모델을 구축하고 학습\n",
    "import torch.nn as nn  #PyTorch의 신경망 모듈을 가져와 신경망 레이어를 정의\n",
    "from torch.utils.data import Dataset, DataLoader  ## PyTorch 데이터 로더를 가져와 데이터셋을 배치로 로드\n",
    "\n",
    "from torchvision import transforms as T  ## Torchvision의 변환 (transforms) 모듈을 가져와 이미지에 대한 전처리 및 증강을 수행\n",
    "import torchvision.models as models ## Torchvision의 시전 훈련된 모델을 가져와 전이 학습에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741239449024,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "pPSV2xB96mHC"
   },
   "outputs": [],
   "source": [
    "## 이미지 전처리를 위한 변환(transform) 파이프라인을 정의\n",
    "## T.Compose를 사용 -> 여러 변환을 순차적으로 적용\n",
    "## 1. T.Resize(256): 이미지를 256X256 크기로 리사이즈\n",
    "## 2. T.RandomCrop(244) : 리 사이즈된 이미지에서 244X244 크기의 랜덤한 영역을 잘라냄\n",
    "## 3. T.ToTensor() : PIL 이미지나 NumPy 배열을 PyTorch 텐서로 변환\n",
    "transform = T.Compose([T.Resize(256), T.RandomCrop(244), T.ToTensor()])\n",
    "\n",
    "class Dataset(Dataset):  ## 사용자 정의 데이터셋 클래스를 정의 , PyTorch의 Dataset 클래스를 상속\n",
    "    def __init__(self, path='train'): ## 초기화 메서드 , 데이터 셋의 경로르 받아 이미지 파일 경로와 레이블을 설정\n",
    "        super(Dataset, self).__init__()  ## 부모 클래스의 초기화 메서드를 호출\n",
    "\n",
    "        bo_path = glob.glob(path+'/bo/*.jpg')  ## 'bo' 폴더 내의 모든 .jpg 파일 경로를 가져옴\n",
    "        notbo_path = glob.glob(path+'/not_bo/*.jpg')  ## 'not bo' 폴더 내의 모든 .jpg 파일 경로를 가져옴\n",
    "        self.img_path = bo_path + notbo_path  ## 'bo'와 'not bo'의 이미지 경로를 합쳐 전체 이미지 경로 리스트를 만듬\n",
    "        self.label_list = [1]*len(bo_path) + [0]*len(notbo_path)  ## 'bo' 이미지에는 레이블 1, 'not bo' 이미지에는 레이블 0을 할당 -> 레이블 리스트를 만듬\n",
    "\n",
    "    def __getitem__(self, index):  ## 데이터셋의 특정 인덱스에 해당하는 샘플을 가져오는 메서드\n",
    "        img = cv2.imread(self.img_path[index])  ## 지정된 인덱스의 이미지 파일을 OpenCV를 사용하여 읽음\n",
    "        img_pil = Image.fromarray(img)  ## OpenCV로 읽은 이미지를 PIL 이미지로 전처리하고 텐서로 변환\n",
    "        self.img_tensor = transform(img_pil)  ## 정의된 transform을 사용하여 PIL 이미지를 전처리 하고 텐서로 변환\n",
    "        self.label_tensor = torch.tensor(self.label_list[index])  ## 해당 이미지의 레이블을 PyTorch 텐서로 변환\n",
    "        return self.img_tensor.to(\"cuda:0\"), self.label_tensor.to(\"cuda:0\")  ## 이미지 텐서와 레이블 텐서를 GPU로 이동하여 반환\n",
    "## 데이터셋의 전체 길이 (샘플 수)를 반환하는 메서드\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1741239451159,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "maje3qTx8Svx"
   },
   "outputs": [],
   "source": [
    "## 'train' 폴더를 사용해 학습용 데이터셋을 생성\n",
    "training_dataset = Dataset('train')\n",
    "## 'vali' 폴더를 사용해 검증용 데이터셋을 생성\n",
    "validation_dataset = Dataset('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741239451988,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "I1TTjCHQ8Z1q"
   },
   "outputs": [],
   "source": [
    "## 학습용 데이터 로더를 생성\n",
    "## - dataset : 학습용 데이터셋을 사용\n",
    "## - batch_size : 한 번에 처리할 데이터 샘플의 수를 8로 설정\n",
    "## - shuffle : 검증 데이터는 섞지 않고 순서대로 사용 , 이는 성능 평가의 일관성을 유지하기 위함\n",
    "training_loader = DataLoader(dataset=training_dataset, batch_size=8, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb3gbG1k9DTj"
   },
   "source": [
    "### 2. 뉴럴네트워크 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8802,
     "status": "ok",
     "timestamp": 1741241476578,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "-bDC_bIO9Fs1",
    "outputId": "a48104b0-8ed5-426c-a518-bdbc575a2532"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:07<00:00, 76.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "## VGG16 모델을 불러옴 , 사전 훈련된 가중치를 사용하지 않고 -> 무작위로 초기화된 모델을 생성\n",
    "#vgg16 = models.vgg16()\n",
    "## VGG16 모델을 불러오고 , ImageNet 데이터셋으로 사전 훈련된 가중치를 사용\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1741241559926,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "kh3FyBwRFJ6W"
   },
   "outputs": [],
   "source": [
    "## VGG16 모델의 모든 파라미터에 대해 반복\n",
    "for param in vgg16.parameters():\n",
    "## 각 파라미터의 REquires_grad 속성을 False로 설정 , 해당 ㅍ파라미터가 학습되지 않도록 함\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1741241568247,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "zUqR4j1MBD6B"
   },
   "outputs": [],
   "source": [
    "## VGG16 모델의 classifier 레이어 중 첫 번째 레이어 ( fully connected layer )의 입력 특징 수를 가져옴\n",
    "## 이는 새로운 classifier를 설계할 떄 입력 크기를 맞추기 위해 필요\n",
    "num_features = vgg16.classifier[0].in_features\n",
    "## VGG16의 classifier 부분을 새로운 Sequential 모듈로 대체\n",
    "## 이 Sequential 모듈은 여러 레이어를 순차적으로 쌓아 구성 , 다음과 같은 레이어로 이루어짐\n",
    "## 1. nn.Linear(num_features, 256) : 입력 특징 수에서 256개의 뉴런으로 연결된 fully connected layer\n",
    "## 2. NN.ReLU() : 활성화 함수로 ReLU를 사용해 비선형성을 추가\n",
    "## 3. nn.Linear(256, 2) : 256개의 뉴런에서 2개의 출력 클래스로 연결된 fully connected layer\n",
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1741241569556,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "WzyhlWqwBbRU"
   },
   "outputs": [],
   "source": [
    "## VGG16 모델을 GPU로 이동 , ' cuda:0'은 첫 번쨰 GPU를 의미 , 이를 통해 GPU가속을 사용 -> 더 빠른 계산을 가능하게 함\n",
    "vgg16 = vgg16.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a1HNOy2CCmz"
   },
   "source": [
    "### 3. 손실함수와 최적화기법 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741241571001,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "mT-WrJYCCFdy"
   },
   "outputs": [],
   "source": [
    "## 손실 함수로 CrossEntropyLoss를 사용 , 이 함수는 다중 클래스 분류 문제에서 자주 사용\n",
    "## 모델의 예측과 실제 레이블 간의 차이를 측정하여 모델이 학습할 수 있도록 함\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "## 최적화 도구로 Adam을 사용 , Adam은 학습률을 자동으로 조정하는 알고리즘\n",
    "## VGG16 모델의 파라미터를 업데이터하는데 사용 , 학습률(lr)은 0.0001로 설정\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fana0fxfCU1f"
   },
   "source": [
    "### 3. 뉴럴네트워크 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18165,
     "status": "ok",
     "timestamp": 1741241589999,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "ws2TI8XQCd46",
    "outputId": "ae1b7459-8646-4c65-e864-2f59d2f30e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  , Loss:  8.621671382337809\n",
      "Epoch:  2  , Loss:  1.7960744048468769\n",
      "Epoch:  3  , Loss:  0.3592872351873666\n",
      "Epoch:  4  , Loss:  0.273036266095005\n",
      "Epoch:  5  , Loss:  0.09288019145606086\n",
      "Epoch:  6  , Loss:  0.07390306067827623\n",
      "Epoch:  7  , Loss:  0.05486678182205651\n",
      "Epoch:  8  , Loss:  0.03361212946037995\n",
      "Epoch:  9  , Loss:  0.026950100000249222\n",
      "Epoch:  10  , Loss:  0.023187731254438404\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  ## 10d 에포크 동안 반복 (각 에포크는 데이터셋 전체를 한 번 학습)\n",
    "    loss_val = 0  ## 각 에포크 시작 시 손실 값을 0으로 초기화 , 에포크 동안 누적할 예정\n",
    "    for itr, data in enumerate(training_loader):  ##학습 데이터 로더에서 배치 단위로 데이터 반복\n",
    "        optimizer.zero_grad()  ## 이전 그래디언트를 0으로 초기화 , 새로운 그래디언트 계산 준비\n",
    "        inputs, labels = data  ## 배치 데이터를 입력과 레이블로 분리\n",
    "        pred = vgg16(inputs)  ## VGG16 모델에 입력을 전달하여 예측값 계산\n",
    "        loss = loss_function(pred, labels)  ## 예측값과 실제 레이블 간의 손실 계산\n",
    "\n",
    "        loss.backward()  ## 손실에 대해 연적파 수행 , 그래디언트 계산\n",
    "\n",
    "        optimizer.step()  ## 계산된 그래디언트를 기반으로 모델 파라미터 업데이트\n",
    "\n",
    "        loss_val += loss.item()  ## 현재 배치의 손실 값을 누적 ( Python 숫자로 변환 )\n",
    "    print(\"Epoch: \", epoch+1, \" , Loss: \", loss_val)  ## 에포크 번호 ( 1부터 시작 )와 총 손실 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G358s49BD2iJ"
   },
   "source": [
    "### 5. 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1741241590366,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "fa_gBqC2D-Hu"
   },
   "outputs": [],
   "source": [
    "pred_list = []  ## 예측된 카테고리를 저장할 리스트 초기화\n",
    "label_list = []  ## 실제 레이블을 저장할 리스트 초기화\n",
    "\n",
    "for itr, data in enumerate(validation_loader):  ## 검증 데이터 로더에서 배치 단위로 데이터 반복\n",
    "    inputs, labels = data  ## 배치 데이터를 입력과 레이블로 분리\n",
    "\n",
    "    pred = vgg16(inputs)  ## VGG16 모델에 입력을 전달하여 예측값 계산\n",
    "    pred_category = torch.argmax(pred, dim=1)  ## 예측값에서 가장 높은 확률의 카테고리 인덱스 추출\n",
    "\n",
    "    pred_list = pred_list + list(pred_category.cpu())  ## 예측된 카테고리를 CPU로 이동 후 리스트에 추가\n",
    "    label_list = label_list + list(labels.cpu())  ## 실제 레이블을 CPU로 이동 후 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741241590399,
     "user": {
      "displayName": "정기태",
      "userId": "15179527016190971408"
     },
     "user_tz": -540
    },
    "id": "UDm1aYumEhOk",
    "outputId": "4c806742-d1bf-422f-c182-4e3367f3e04f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "accu = np.mean( np.array(pred_list) == np.array(label_list) )  ## 예측값과 실제 레이블을 비교하여 정확도 계산 ( 평균 )\n",
    "print(\"Validation accuracy: \", accu*100)  ## 검증 정확도를 백분율로 변환하여 출력"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOiU8+TWsoQi9bY0g66hARr",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
